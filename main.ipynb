{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89208a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "\n",
    "def batch_format_and_save_images(input_folder, output_folder, batch_size=64, target_size=224):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    total = len(image_files)\n",
    "    for i in range(0, total, batch_size):\n",
    "        batch_files = image_files[i:i+batch_size]\n",
    "        for fname in batch_files:\n",
    "            in_path = os.path.join(input_folder, fname)\n",
    "            out_path = os.path.join(output_folder, fname)\n",
    "            try:\n",
    "                arr = load_and_pad_square(in_path, target_size=target_size)\n",
    "                img = array_to_img(arr)\n",
    "                img.save(out_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {fname}: {e}\")\n",
    "        print(f\"Processed {min(i+batch_size, total)}/{total} images.\")\n",
    "\n",
    "# Example usage:\n",
    "# batch_format_and_save_images(\"images-1\", \"images-1-formatted\", batch_size=64, target_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5a869fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Malthe\\AppData\\Local\\Temp\\ipykernel_13628\\2837782236.py:20: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize(new_size, Image.LANCZOS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 64/5000 images.\n",
      "Processed 128/5000 images.\n",
      "Processed 192/5000 images.\n",
      "Processed 256/5000 images.\n",
      "Processed 320/5000 images.\n",
      "Processed 384/5000 images.\n",
      "Processed 448/5000 images.\n",
      "Processed 512/5000 images.\n",
      "Processed 576/5000 images.\n",
      "Processed 640/5000 images.\n",
      "Processed 704/5000 images.\n",
      "Processed 768/5000 images.\n",
      "Processed 832/5000 images.\n",
      "Processed 896/5000 images.\n",
      "Processed 960/5000 images.\n",
      "Processed 1024/5000 images.\n",
      "Processed 1088/5000 images.\n",
      "Processed 1152/5000 images.\n",
      "Processed 1216/5000 images.\n",
      "Processed 1280/5000 images.\n",
      "Processed 1344/5000 images.\n",
      "Processed 1408/5000 images.\n",
      "Processed 1472/5000 images.\n",
      "Processed 1536/5000 images.\n",
      "Processed 1600/5000 images.\n",
      "Processed 1664/5000 images.\n",
      "Processed 1728/5000 images.\n",
      "Processed 1792/5000 images.\n",
      "Processed 1856/5000 images.\n",
      "Processed 1920/5000 images.\n",
      "Processed 1984/5000 images.\n",
      "Processed 2048/5000 images.\n",
      "Processed 2112/5000 images.\n",
      "Processed 2176/5000 images.\n",
      "Processed 2240/5000 images.\n",
      "Processed 2304/5000 images.\n",
      "Processed 2368/5000 images.\n",
      "Processed 2432/5000 images.\n",
      "Processed 2496/5000 images.\n",
      "Processed 2560/5000 images.\n",
      "Processed 2624/5000 images.\n",
      "Processed 2688/5000 images.\n",
      "Processed 2752/5000 images.\n",
      "Processed 2816/5000 images.\n",
      "Processed 2880/5000 images.\n",
      "Processed 2944/5000 images.\n",
      "Processed 3008/5000 images.\n",
      "Processed 3072/5000 images.\n",
      "Processed 3136/5000 images.\n",
      "Processed 3200/5000 images.\n",
      "Processed 3264/5000 images.\n",
      "Processed 3328/5000 images.\n",
      "Processed 3392/5000 images.\n",
      "Processed 3456/5000 images.\n",
      "Processed 3520/5000 images.\n",
      "Processed 3584/5000 images.\n",
      "Processed 3648/5000 images.\n",
      "Processed 3712/5000 images.\n",
      "Processed 3776/5000 images.\n",
      "Processed 3840/5000 images.\n",
      "Processed 3904/5000 images.\n",
      "Processed 3968/5000 images.\n",
      "Processed 4032/5000 images.\n",
      "Processed 4096/5000 images.\n",
      "Processed 4160/5000 images.\n",
      "Processed 4224/5000 images.\n",
      "Processed 4288/5000 images.\n",
      "Processed 4352/5000 images.\n",
      "Processed 4416/5000 images.\n",
      "Processed 4480/5000 images.\n",
      "Processed 4544/5000 images.\n",
      "Processed 4608/5000 images.\n",
      "Processed 4672/5000 images.\n",
      "Processed 4736/5000 images.\n",
      "Processed 4800/5000 images.\n",
      "Processed 4864/5000 images.\n",
      "Processed 4928/5000 images.\n",
      "Processed 4992/5000 images.\n",
      "Processed 5000/5000 images.\n",
      "Processed 64/4899 images.\n",
      "Processed 128/4899 images.\n",
      "Processed 192/4899 images.\n",
      "Processed 256/4899 images.\n",
      "Processed 320/4899 images.\n",
      "Processed 384/4899 images.\n",
      "Processed 448/4899 images.\n",
      "Processed 512/4899 images.\n",
      "Processed 576/4899 images.\n",
      "Processed 640/4899 images.\n",
      "Processed 704/4899 images.\n",
      "Processed 768/4899 images.\n",
      "Processed 832/4899 images.\n",
      "Processed 896/4899 images.\n",
      "Processed 960/4899 images.\n",
      "Processed 1024/4899 images.\n",
      "Processed 1088/4899 images.\n",
      "Processed 1152/4899 images.\n",
      "Processed 1216/4899 images.\n",
      "Processed 1280/4899 images.\n",
      "Processed 1344/4899 images.\n",
      "Processed 1408/4899 images.\n",
      "Processed 1472/4899 images.\n",
      "Processed 1536/4899 images.\n",
      "Processed 1600/4899 images.\n",
      "Processed 1664/4899 images.\n",
      "Processed 1728/4899 images.\n",
      "Processed 1792/4899 images.\n",
      "Processed 1856/4899 images.\n",
      "Processed 1920/4899 images.\n",
      "Processed 1984/4899 images.\n",
      "Processed 2048/4899 images.\n",
      "Processed 2112/4899 images.\n",
      "Processed 2176/4899 images.\n",
      "Processed 2240/4899 images.\n",
      "Processed 2304/4899 images.\n",
      "Processed 2368/4899 images.\n",
      "Processed 2432/4899 images.\n",
      "Processed 2496/4899 images.\n",
      "Processed 2560/4899 images.\n",
      "Processed 2624/4899 images.\n",
      "Processed 2688/4899 images.\n",
      "Processed 2752/4899 images.\n",
      "Processed 2816/4899 images.\n",
      "Processed 2880/4899 images.\n",
      "Processed 2944/4899 images.\n",
      "Processed 3008/4899 images.\n",
      "Processed 3072/4899 images.\n",
      "Processed 3136/4899 images.\n",
      "Processed 3200/4899 images.\n",
      "Processed 3264/4899 images.\n",
      "Processed 3328/4899 images.\n",
      "Processed 3392/4899 images.\n",
      "Processed 3456/4899 images.\n",
      "Processed 3520/4899 images.\n",
      "Processed 3584/4899 images.\n",
      "Processed 3648/4899 images.\n",
      "Processed 3712/4899 images.\n",
      "Processed 3776/4899 images.\n",
      "Processed 3840/4899 images.\n",
      "Processed 3904/4899 images.\n",
      "Processed 3968/4899 images.\n",
      "Processed 4032/4899 images.\n",
      "Processed 4096/4899 images.\n",
      "Processed 4160/4899 images.\n",
      "Processed 4224/4899 images.\n",
      "Processed 4288/4899 images.\n",
      "Processed 4352/4899 images.\n",
      "Processed 4416/4899 images.\n",
      "Processed 4480/4899 images.\n",
      "Processed 4544/4899 images.\n",
      "Processed 4608/4899 images.\n",
      "Processed 4672/4899 images.\n",
      "Processed 4736/4899 images.\n",
      "Processed 4800/4899 images.\n",
      "Processed 4864/4899 images.\n",
      "Processed 4899/4899 images.\n",
      "Processed 64/500 images.\n",
      "Processed 128/500 images.\n",
      "Processed 192/500 images.\n",
      "Processed 256/500 images.\n",
      "Processed 320/500 images.\n",
      "Processed 384/500 images.\n",
      "Processed 448/500 images.\n",
      "Processed 500/500 images.\n",
      "Processed 64/500 images.\n",
      "Processed 128/500 images.\n",
      "Processed 192/500 images.\n",
      "Processed 256/500 images.\n",
      "Processed 320/500 images.\n",
      "Processed 384/500 images.\n",
      "Processed 448/500 images.\n",
      "Processed 500/500 images.\n",
      "Processed 64/1500 images.\n",
      "Processed 128/1500 images.\n",
      "Processed 192/1500 images.\n",
      "Processed 256/1500 images.\n",
      "Processed 320/1500 images.\n",
      "Processed 384/1500 images.\n",
      "Processed 448/1500 images.\n",
      "Processed 512/1500 images.\n",
      "Processed 576/1500 images.\n",
      "Processed 640/1500 images.\n",
      "Processed 704/1500 images.\n",
      "Processed 768/1500 images.\n",
      "Processed 832/1500 images.\n",
      "Processed 896/1500 images.\n",
      "Processed 960/1500 images.\n",
      "Processed 1024/1500 images.\n",
      "Processed 1088/1500 images.\n",
      "Processed 1152/1500 images.\n",
      "Processed 1216/1500 images.\n",
      "Processed 1280/1500 images.\n",
      "Processed 1344/1500 images.\n",
      "Processed 1408/1500 images.\n",
      "Processed 1472/1500 images.\n",
      "Processed 1500/1500 images.\n",
      "Processed 64/1500 images.\n",
      "Processed 128/1500 images.\n",
      "Processed 192/1500 images.\n",
      "Processed 256/1500 images.\n",
      "Processed 320/1500 images.\n",
      "Processed 384/1500 images.\n",
      "Processed 448/1500 images.\n",
      "Processed 512/1500 images.\n",
      "Processed 576/1500 images.\n",
      "Processed 640/1500 images.\n",
      "Processed 704/1500 images.\n",
      "Processed 768/1500 images.\n",
      "Processed 832/1500 images.\n",
      "Processed 896/1500 images.\n",
      "Processed 960/1500 images.\n",
      "Processed 1024/1500 images.\n",
      "Processed 1088/1500 images.\n",
      "Processed 1152/1500 images.\n",
      "Processed 1216/1500 images.\n",
      "Processed 1280/1500 images.\n",
      "Processed 1344/1500 images.\n",
      "Processed 1408/1500 images.\n",
      "Processed 1472/1500 images.\n",
      "Processed 1500/1500 images.\n",
      "Processed 64/1500 images.\n",
      "Processed 128/1500 images.\n",
      "Processed 192/1500 images.\n",
      "Processed 256/1500 images.\n",
      "Processed 320/1500 images.\n",
      "Processed 384/1500 images.\n",
      "Processed 448/1500 images.\n",
      "Processed 512/1500 images.\n",
      "Processed 576/1500 images.\n",
      "Processed 640/1500 images.\n",
      "Processed 704/1500 images.\n",
      "Processed 768/1500 images.\n",
      "Processed 832/1500 images.\n",
      "Processed 896/1500 images.\n",
      "Processed 960/1500 images.\n",
      "Processed 1024/1500 images.\n",
      "Processed 1088/1500 images.\n",
      "Processed 1152/1500 images.\n",
      "Processed 1216/1500 images.\n",
      "Processed 1280/1500 images.\n",
      "Processed 1344/1500 images.\n",
      "Processed 1408/1500 images.\n",
      "Processed 1472/1500 images.\n",
      "Processed 1500/1500 images.\n",
      "Processed 64/1500 images.\n",
      "Processed 128/1500 images.\n",
      "Processed 192/1500 images.\n",
      "Processed 256/1500 images.\n",
      "Processed 320/1500 images.\n",
      "Processed 384/1500 images.\n",
      "Processed 448/1500 images.\n",
      "Processed 512/1500 images.\n",
      "Processed 576/1500 images.\n",
      "Processed 640/1500 images.\n",
      "Processed 704/1500 images.\n",
      "Processed 768/1500 images.\n",
      "Processed 832/1500 images.\n",
      "Processed 896/1500 images.\n",
      "Processed 960/1500 images.\n",
      "Processed 1024/1500 images.\n",
      "Processed 1088/1500 images.\n",
      "Processed 1152/1500 images.\n",
      "Processed 1216/1500 images.\n",
      "Processed 1280/1500 images.\n",
      "Processed 1344/1500 images.\n",
      "Processed 1408/1500 images.\n",
      "Processed 1472/1500 images.\n",
      "Processed 1500/1500 images.\n",
      "Processed 64/1500 images.\n",
      "Processed 128/1500 images.\n",
      "Processed 192/1500 images.\n",
      "Processed 256/1500 images.\n",
      "Processed 320/1500 images.\n",
      "Processed 384/1500 images.\n",
      "Processed 448/1500 images.\n",
      "Processed 512/1500 images.\n",
      "Processed 576/1500 images.\n",
      "Processed 640/1500 images.\n",
      "Processed 704/1500 images.\n",
      "Processed 768/1500 images.\n",
      "Processed 832/1500 images.\n",
      "Processed 896/1500 images.\n",
      "Processed 960/1500 images.\n",
      "Processed 1024/1500 images.\n",
      "Processed 1088/1500 images.\n",
      "Processed 1152/1500 images.\n",
      "Processed 1216/1500 images.\n",
      "Processed 1280/1500 images.\n",
      "Processed 1344/1500 images.\n",
      "Processed 1408/1500 images.\n",
      "Processed 1472/1500 images.\n",
      "Processed 1500/1500 images.\n",
      "Processed 64/1500 images.\n",
      "Processed 128/1500 images.\n",
      "Processed 192/1500 images.\n",
      "Processed 256/1500 images.\n",
      "Processed 320/1500 images.\n",
      "Processed 384/1500 images.\n",
      "Processed 448/1500 images.\n",
      "Processed 512/1500 images.\n",
      "Processed 576/1500 images.\n",
      "Processed 640/1500 images.\n",
      "Processed 704/1500 images.\n",
      "Processed 768/1500 images.\n",
      "Processed 832/1500 images.\n",
      "Processed 896/1500 images.\n",
      "Processed 960/1500 images.\n",
      "Processed 1024/1500 images.\n",
      "Processed 1088/1500 images.\n",
      "Processed 1152/1500 images.\n",
      "Processed 1216/1500 images.\n",
      "Processed 1280/1500 images.\n",
      "Processed 1344/1500 images.\n",
      "Processed 1408/1500 images.\n",
      "Processed 1472/1500 images.\n",
      "Processed 1500/1500 images.\n"
     ]
    }
   ],
   "source": [
    "batch_format_and_save_images(\"images-1\", \"images-1-formatted\", batch_size=64, target_size=224) \n",
    "batch_format_and_save_images(\"images-2\", \"images-2-formatted\", batch_size=64, target_size=224) \n",
    "batch_format_and_save_images(\"images-3\", \"images-3-formatted\", batch_size=64, target_size=224)\n",
    "batch_format_and_save_images(\"images-4\", \"images-4-formatted\", batch_size=64, target_size=224)\n",
    "batch_format_and_save_images(\"images-5\", \"images-5-formatted\", batch_size=64, target_size=224)\n",
    "batch_format_and_save_images(\"images-6\", \"images-6-formatted\", batch_size=64, target_size=224)\n",
    "batch_format_and_save_images(\"images-7\", \"images-7-formatted\", batch_size=64, target_size=224)\n",
    "batch_format_and_save_images(\"images-8\", \"images-8-formatted\", batch_size=64, target_size=224)\n",
    "batch_format_and_save_images(\"images-9\", \"images-9-formatted\", batch_size=64, target_size=224)\n",
    "batch_format_and_save_images(\"images-10\", \"images-10-formatted\", batch_size=64, target_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb007870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       id;angle;file\n",
      "0  6886d4d11c95c1200fdeebd5;-3.271121386604701;68...\n",
      "1  6888527baf0ce92103121164;-2.700237618768623;68...\n",
      "2  68875f2a1c95c1200fdef81d;-7.312921806443301;68...\n",
      "3  68877c8b1c95c1200fdefd45;0.9269297042023048;68...\n",
      "4  688756641c95c1200fdef682;2.1856050617065783;68...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with the format of \"train-ds-ft.csv\"\n",
    "df = pd.read_csv(\"training-ds-ft.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a51e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "# Build regression model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_and_pad_square(img_path, target_size=224):\n",
    "    # Load image\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    # Compute scale and new size\n",
    "    ratio = float(target_size) / max(img.size)\n",
    "    new_size = tuple([int(x * ratio) for x in img.size])\n",
    "    img = img.resize(new_size, Image.LANCZOS)\n",
    "    # Create new black square image and paste resized image onto center\n",
    "    new_img = Image.new(\"RGB\", (target_size, target_size))\n",
    "    paste_pos = ((target_size - new_size[0]) // 2, (target_size - new_size[1]) // 2)\n",
    "    new_img.paste(img, paste_pos)\n",
    "    # Convert to array\n",
    "    arr = img_to_array(new_img)\n",
    "    return arr\n",
    "# Update input shape and image loading\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "# Parse the CSV to split columns\n",
    "df_split = df['id;angle;file'].str.split(';', expand=True)\n",
    "df_split.columns = ['id', 'angle', 'file']\n",
    "\n",
    "# List all image files in the directory\n",
    "image_dir = \"images-1-formatted\"\n",
    "all_image_files = set(os.listdir(image_dir))\n",
    "\n",
    "# Prepare matched image paths and labels\n",
    "matched_image_paths = []\n",
    "matched_angles = []\n",
    "\n",
    "for fname in all_image_files:\n",
    "    row = df_split[df_split['file'] == fname]\n",
    "    if not row.empty:\n",
    "        matched_image_paths.append(f\"{image_dir}/{fname}\")\n",
    "        matched_angles.append(float(row.iloc[0]['angle']))\n",
    "\n",
    "angles = np.array(matched_angles)\n",
    "# Load the formatted images\n",
    "X = []\n",
    "for img_path in matched_image_paths:\n",
    "    img = load_img(img_path, target_size=(64, 64))\n",
    "    img_arr = img_to_array(img)\n",
    "    X.append(img_arr)\n",
    "X = np.array(X) / 255.0\n",
    "# Load images and preprocess\n",
    "#X = []\n",
    "#for img_path in matched_image_paths:\n",
    " #   img_arr = load_and_pad_square(img_path, target_size=224)\n",
    "  #  X.append(img_arr)\n",
    "#X = np.array(X, dtype=np.float32) / 255.0\n",
    "\n",
    "# Custom reward metric\n",
    "def within_margin(y_true, y_pred):\n",
    "    return K.mean(K.cast(K.less_equal(K.abs(y_true - y_pred), 1), K.floatx()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4722e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Malthe\\AppData\\Local\\Temp\\ipykernel_13628\\1711812072.py:20: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img = img.resize(new_size, Image.LANCZOS)\n"
     ]
    }
   ],
   "source": [
    "other_image_dir = \"images-2\"\n",
    "other_image_files = set(os.listdir(other_image_dir))\n",
    "\n",
    "# Find matching images in the new folder using df_split\n",
    "other_matched_image_paths = []\n",
    "other_matched_angles = []\n",
    "\n",
    "for idx, row in df_split.iterrows():\n",
    "    fname = row['file']\n",
    "    if fname in other_image_files:\n",
    "        other_matched_image_paths.append(f\"{other_image_dir}/{fname}\")\n",
    "        other_matched_angles.append(float(row['angle']))\n",
    "\n",
    "if other_matched_image_paths:\n",
    "    other_angles = np.array(other_matched_angles)\n",
    "\n",
    "    # Load and preprocess images\n",
    "    other_X = []\n",
    "    for img_path in other_matched_image_paths:\n",
    "        img_arr = load_and_pad_square(img_path, target_size=(224))\n",
    "        other_X.append(img_arr)\n",
    "    other_X = np.array(other_X) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87c53e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 64, 64, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     23\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m callbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 24\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m other_angles_rad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdeg2rad(other_angles)\n\u001b[0;32m     31\u001b[0m other_targets \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([np\u001b[38;5;241m.\u001b[39mcos(other_angles_rad), np\u001b[38;5;241m.\u001b[39msin(other_angles_rad)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filerogt2dd0.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Malthe\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks, backend as K\n",
    "\n",
    "# angles in degrees, convert to radians\n",
    "angles_rad = np.deg2rad(angles)\n",
    "targets = np.stack([np.cos(angles_rad), np.sin(angles_rad)], axis=1)\n",
    "def build_custom_cnn(input_shape=(224, 224, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(2, activation='linear')  # Output 2 values: cos and sin\n",
    "    ])\n",
    "    return model\n",
    "model = build_custom_cnn(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X, targets,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "other_angles_rad = np.deg2rad(other_angles)\n",
    "other_targets = np.stack([np.cos(other_angles_rad), np.sin(other_angles_rad)], axis=1)\n",
    "loss, mse = model.evaluate(other_X, other_targets, verbose=2)\n",
    "print(f\"Performance on {other_image_dir}: Loss={loss:.4f}, MSE={mse:.4f}\")\n",
    "model.save_weights(\"cossin.h5\")\n",
    "import numpy as np\n",
    "\n",
    "# Predict cos/sin for the evaluation set in batches to avoid MemoryError\n",
    "preds = model.predict(other_X, batch_size=32)\n",
    "\n",
    "# Convert predictions and targets to angles in degrees\n",
    "pred_angles_rad = np.arctan2(preds[:, 1], preds[:, 0])\n",
    "pred_angles_deg = np.rad2deg(pred_angles_rad)\n",
    "\n",
    "true_angles_deg = other_angles  # Assuming other_angles is in degrees\n",
    "\n",
    "# Custom evaluation metric: percentage within margin (e.g., 0.8 degrees)\n",
    "margin = 1\n",
    "angle_diff = np.abs(pred_angles_deg - true_angles_deg)\n",
    "# Handle wrap-around at 180/-180\n",
    "angle_diff = np.minimum(angle_diff, 360 - angle_diff)\n",
    "within_margin = np.mean(angle_diff <= margin)\n",
    "\n",
    "print(f\"Custom evaluation: {within_margin*100:.2f}% predictions within {margin} degrees of ground truth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
